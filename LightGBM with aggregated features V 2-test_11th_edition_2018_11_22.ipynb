{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79cde592-cafb-467a-9e13-13297afede14",
    "_uuid": "208338288dcff3afa0867b306720403185a0f482"
   },
   "source": [
    "### This kernel is forked from https://www.kaggle.com/bminixhofer/aggregated-features-lightgbm . I have done some changes to get better score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "033852ed-2dd3-4bc3-bec1-ac3481ab175f",
    "_kg_hide-input": true,
    "_uuid": "af7422df064b7f16934cca9e86e8213bc9c667e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "NFOLDS = 5\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "94a03718-1718-4981-88ef-532efcb435ee",
    "_uuid": "5d8e0a1a86fe5fbfa5162d3180d0b1ebea94f97d"
   },
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "bc719fcf-f418-4db5-a4fa-ebfa27716521",
    "_uuid": "02aad0b977053435e089bd189ea45e4a88731e87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>avg_days_up_user</th>\n",
       "      <th>avg_times_up_user</th>\n",
       "      <th>n_user_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>Свердловская область</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>Private</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.12789</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>Самарская область</td>\n",
       "      <td>Самара</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Private</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>Private</td>\n",
       "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>0.43177</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>Татарстан</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>...</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>286</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>Company</td>\n",
       "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
       "      <td>796.0</td>\n",
       "      <td>0.80323</td>\n",
       "      <td>16.714286</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>Волгоградская область</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>...</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>Private</td>\n",
       "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.20797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id                 region              city  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9   Свердловская область      Екатеринбург   \n",
       "1  2dac0150717d  39aeb48f0017      Самарская область            Самара   \n",
       "2  ba83aefab5dc  91e2f88dd6e3     Ростовская область    Ростов-на-Дону   \n",
       "3  02996f1dd2ea  bf5cccea572d              Татарстан  Набережные Челны   \n",
       "4  7c90be56d2ab  ef50846afc0b  Волгоградская область         Волгоград   \n",
       "\n",
       "  parent_category_name               category_name  \\\n",
       "0          Личные вещи  Товары для детей и игрушки   \n",
       "1      Для дома и дачи           Мебель и интерьер   \n",
       "2  Бытовая электроника               Аудио и видео   \n",
       "3          Личные вещи  Товары для детей и игрушки   \n",
       "4            Транспорт                  Автомобили   \n",
       "\n",
       "                       param_1     param_2 param_3                  title  \\\n",
       "0    Постельные принадлежности         NaN     NaN  Кокоби(кокон для сна)   \n",
       "1                       Другое         NaN     NaN      Стойка для Одежды   \n",
       "2  Видео, DVD и Blu-ray плееры         NaN     NaN         Philips bluray   \n",
       "3         Автомобильные кресла         NaN     NaN             Автокресло   \n",
       "4                   С пробегом  ВАЗ (LADA)    2110         ВАЗ 2110, 2003   \n",
       "\n",
       "       ...         price  item_seq_number  activation_date user_type  \\\n",
       "0      ...         400.0                2       2017-03-28   Private   \n",
       "1      ...        3000.0               19       2017-03-26   Private   \n",
       "2      ...        4000.0                9       2017-03-20   Private   \n",
       "3      ...        2200.0              286       2017-03-25   Company   \n",
       "4      ...       40000.0                3       2017-03-16   Private   \n",
       "\n",
       "                                               image image_top_1  \\\n",
       "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...      1008.0   \n",
       "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...       692.0   \n",
       "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...      3032.0   \n",
       "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...       796.0   \n",
       "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...      2264.0   \n",
       "\n",
       "   deal_probability  avg_days_up_user  avg_times_up_user  n_user_items  \n",
       "0           0.12789          8.000000           2.000000             2  \n",
       "1           0.00000               NaN                NaN             1  \n",
       "2           0.43177          4.428571           1.142857             9  \n",
       "3           0.80323         16.714286           2.642857            32  \n",
       "4           0.20797               NaN                NaN             1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../Avito/data/train.csv')\n",
    "test = pd.read_csv('../../Avito/data/test.csv')\n",
    "gp = pd.read_csv('aggregated_features.csv') \n",
    "train = train.merge(gp, on='user_id', how='left')\n",
    "test = test.merge(gp, on='user_id', how='left')\n",
    "\n",
    "agg_cols = list(gp.columns)[1:]\n",
    "\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78cc3f11-d2c4-4ed8-a7b8-ba44f884c3d6",
    "_uuid": "be70118249f82d7e85cf7ee525303bc4d580932e"
   },
   "source": [
    "# Feature Engineering\n",
    "### Text cleaning does not help So, I am commenting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = pd.read_csv('avito_region_city_features.csv') \n",
    "train = train.merge(city, on=['region', 'city'], how='left')\n",
    "test = test.merge(city, on=['region', 'city'], how='left')\n",
    "\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>n_user_items</th>\n",
       "      <th>city_region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat_lon_hdbscan_cluster_05_03</th>\n",
       "      <th>lat_lon_hdbscan_cluster_10_03</th>\n",
       "      <th>lat_lon_hdbscan_cluster_20_03</th>\n",
       "      <th>region_id</th>\n",
       "      <th>city_region_id</th>\n",
       "      <th>image_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>Свердловская область</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Екатеринбург Свердловская область</td>\n",
       "      <td>56.838926</td>\n",
       "      <td>60.605702</td>\n",
       "      <td>65</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>477</td>\n",
       "      <td>0.906962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>Самарская область</td>\n",
       "      <td>Самара</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Самара Самарская область</td>\n",
       "      <td>53.241504</td>\n",
       "      <td>50.221246</td>\n",
       "      <td>58</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>1370</td>\n",
       "      <td>0.635181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Ростов-на-Дону Ростовская область</td>\n",
       "      <td>47.235714</td>\n",
       "      <td>39.701505</td>\n",
       "      <td>46</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1346</td>\n",
       "      <td>0.720701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>Татарстан</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>Набережные Челны Татарстан</td>\n",
       "      <td>55.718505</td>\n",
       "      <td>52.372104</td>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>982</td>\n",
       "      <td>0.413587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>Волгоградская область</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Волгоград Волгоградская область</td>\n",
       "      <td>48.708048</td>\n",
       "      <td>44.513303</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>327</td>\n",
       "      <td>0.288239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id                 region              city  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9   Свердловская область      Екатеринбург   \n",
       "1  2dac0150717d  39aeb48f0017      Самарская область            Самара   \n",
       "2  ba83aefab5dc  91e2f88dd6e3     Ростовская область    Ростов-на-Дону   \n",
       "3  02996f1dd2ea  bf5cccea572d              Татарстан  Набережные Челны   \n",
       "4  7c90be56d2ab  ef50846afc0b  Волгоградская область         Волгоград   \n",
       "\n",
       "  parent_category_name               category_name  \\\n",
       "0          Личные вещи  Товары для детей и игрушки   \n",
       "1      Для дома и дачи           Мебель и интерьер   \n",
       "2  Бытовая электроника               Аудио и видео   \n",
       "3          Личные вещи  Товары для детей и игрушки   \n",
       "4            Транспорт                  Автомобили   \n",
       "\n",
       "                       param_1     param_2 param_3                  title  \\\n",
       "0    Постельные принадлежности         NaN     NaN  Кокоби(кокон для сна)   \n",
       "1                       Другое         NaN     NaN      Стойка для Одежды   \n",
       "2  Видео, DVD и Blu-ray плееры         NaN     NaN         Philips bluray   \n",
       "3         Автомобильные кресла         NaN     NaN             Автокресло   \n",
       "4                   С пробегом  ВАЗ (LADA)    2110         ВАЗ 2110, 2003   \n",
       "\n",
       "         ...        n_user_items                        city_region  \\\n",
       "0        ...                   2  Екатеринбург Свердловская область   \n",
       "1        ...                   1           Самара Самарская область   \n",
       "2        ...                   9  Ростов-на-Дону Ростовская область   \n",
       "3        ...                  32         Набережные Челны Татарстан   \n",
       "4        ...                   1    Волгоград Волгоградская область   \n",
       "\n",
       "    latitude  longitude lat_lon_hdbscan_cluster_05_03  \\\n",
       "0  56.838926  60.605702                            65   \n",
       "1  53.241504  50.221246                            58   \n",
       "2  47.235714  39.701505                            46   \n",
       "3  55.718505  52.372104                            55   \n",
       "4  48.708048  44.513303                            31   \n",
       "\n",
       "  lat_lon_hdbscan_cluster_10_03  lat_lon_hdbscan_cluster_20_03  region_id  \\\n",
       "0                            38                             21         19   \n",
       "1                            36                             19         17   \n",
       "2                            40                              9         16   \n",
       "3                            33                             18         21   \n",
       "4                            17                             -1          4   \n",
       "\n",
       "   city_region_id  image_confidence  \n",
       "0             477          0.906962  \n",
       "1            1370          0.635181  \n",
       "2            1346          0.720701  \n",
       "3             982          0.413587  \n",
       "4             327          0.288239  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence = pd.read_csv('results/total_result.csv', usecols=[\"image\", \"image_confidence\"]) \n",
    "confidence1 = pd.read_csv('results/total_result1.csv', usecols=[\"image\", \"image_confidence\"]) \n",
    "train = train.merge(confidence, on='image', how='left')\n",
    "test = test.merge(confidence1, on='image', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img = pd.read_csv('train_image_top_1_features.csv') \n",
    "test_img = pd.read_csv('test_image_top_1_features.csv')\n",
    "train.drop(['image_top_1'], axis=1, inplace=True)\n",
    "test.drop(['image_top_1'], axis=1, inplace=True)\n",
    "\n",
    "train = train.merge(train_img, on=['item_id'], how='left')\n",
    "test = test.merge(test_img, on=['item_id'], how='left')\n",
    "\n",
    "del train_img, test_img\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "13d87e1c-0eed-47cb-926b-1b1c7d618900",
    "_uuid": "138fe214a8f82385aa344f6c17e78faf352fb690"
   },
   "outputs": [],
   "source": [
    "# def cleanup(s):                      \n",
    "#     \"\"\"\n",
    "#     function to clean text data\n",
    "    \n",
    "#     \"\"\"\n",
    "#     s = str(s)\n",
    "#     s = s.lower()\n",
    "# #     s = re.sub('\\s\\W',' ',s)\n",
    "# #     s = re.sub(\"https\\S+\\w+\",\"\",s)\n",
    "# #     s=[word if word not in ss else \"\" for word in TweetTokenizer().tokenize(s)]\n",
    "# #     s = \" \".join(s)\n",
    "# #     s = re.sub('rt*.@\\w+',' ',s)\n",
    "# #     s = re.sub('@\\w+',' ',s)\n",
    "# #     s = re.sub('\\W,\\s',' ',s)\n",
    "# #     s = re.sub(r'[^\\w,]', ' ', s)\n",
    "#     s = re.sub(\"\\d+\", \"\", s)\n",
    "#     s = re.sub('\\s+',' ',s)\n",
    "#     s = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', s)\n",
    "# #     s = s.replace(\".co\",\"\")\n",
    "# #     s = s.replace(\",\",\"\")\n",
    "# #     s = s.replace(\"[\\w*\",\" \")\n",
    "#     s = ''.join(''.join(a)[:2] for _, a in itertools.groupby(s))\n",
    "#     return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "41e1111d-674e-4c86-b232-c0086832ee6d",
    "_uuid": "9c60409e1dc6c618f229e15c2b368660385c2ec1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for df in [train, test]:\n",
    "    \n",
    "    df['image_confidence'].fillna(0.0, inplace=True)\n",
    "    \n",
    "    \n",
    "    df['description'].fillna('unknowndesc', inplace=True)\n",
    "    df['title'].fillna('unknowntitle', inplace=True)\n",
    "\n",
    "    df['weekday'] = pd.to_datetime(df['activation_date']).dt.day\n",
    "    \n",
    "    for col in ['description', 'title']:\n",
    "        df['num_words_' + col] = df[col].apply(lambda comment: len(comment.split()))\n",
    "        df['num_unique_words_' + col] = df[col].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "\n",
    "    df['words_vs_unique_title'] = df['num_unique_words_title'] / df['num_words_title'] * 100\n",
    "    df['words_vs_unique_description'] = df['num_unique_words_description'] / df['num_words_description'] * 100\n",
    "    \n",
    "    df['city'] = df['region'] + '_' + df['city']\n",
    "    df['num_desc_punct'] = df['description'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "    \n",
    "    for col in agg_cols:\n",
    "        df[col].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\iii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "8d61ada6-8f3a-4b58-baad-199589122985",
    "_uuid": "cc558a03cbddc3954b01783636785cdee6cf954a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1503424, 105957), (1503424, 17000))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer_title = CountVectorizer(stop_words=stopwords.words('russian'), lowercase=True, min_df=2)\n",
    "\n",
    "title_counts = count_vectorizer_title.fit_transform(train['title'].append(test['title']))\n",
    "\n",
    "train_title_counts = title_counts[:len(train)]\n",
    "test_title_counts = title_counts[len(train):]\n",
    "\n",
    "\n",
    "count_vectorizer_desc = TfidfVectorizer(stop_words=stopwords.words('russian'), \n",
    "                                        lowercase=True, ngram_range=(1, 2),\n",
    "                                        max_features=17000)\n",
    "\n",
    "desc_counts = count_vectorizer_desc.fit_transform(train['description'].append(test['description']))\n",
    "\n",
    "train_desc_counts = desc_counts[:len(train)]\n",
    "test_desc_counts = desc_counts[len(train):]\n",
    "\n",
    "train_title_counts.shape, train_desc_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "56338e56-c266-4342-a8f3-10621db49dee",
    "_uuid": "cc6f15f981f05ad9b1e89ab7acb54ea2350278c6"
   },
   "outputs": [],
   "source": [
    "target = 'deal_probability'\n",
    "predictors = [\n",
    "    'num_desc_punct', \n",
    "    'words_vs_unique_description', 'num_unique_words_description', 'num_unique_words_title', 'num_words_description', 'num_words_title',\n",
    "    'avg_times_up_user', 'avg_days_up_user', 'n_user_items', \n",
    "    'price', 'item_seq_number', 'image_confidence', \n",
    "]\n",
    "categorical = [\n",
    "    'image_top_1', 'param_1', 'param_2', 'param_3', \n",
    "    'city', 'region', 'category_name', 'parent_category_name', 'user_type',\n",
    "        'city_region_id'\n",
    "]\n",
    "\n",
    "predictors = predictors + categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "7695c1a1-06cf-40e6-8792-77b62f48262a",
    "_uuid": "0bcde9bb9b9b26347c7db7da47123c6fec40860e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n",
      "Transforming {feature}...\n"
     ]
    }
   ],
   "source": [
    "for feature in categorical:\n",
    "    print('Transforming {feature}...')\n",
    "    encoder = LabelEncoder()\n",
    "    train[feature].fillna('unknown',inplace=True)\n",
    "    test[feature].fillna('unknown',inplace=True)\n",
    "    encoder.fit(train[feature].append(test[feature]).astype(str))\n",
    "    \n",
    "    train[feature] = encoder.transform(train[feature].astype(str))\n",
    "    test[feature] = encoder.transform(test[feature].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee2f2491-7997-48eb-b022-ba13899e759e",
    "_uuid": "a0f573f22ce96488b58b414b2e49c3d499d87a94"
   },
   "source": [
    "# Hyper Parameter Tuning\n",
    "\n",
    "### I did it on cloud so I m just commenting it out to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "fdd39943-2e02-4403-9413-aaac70f5511f",
    "_uuid": "e3b3d12868ab835e78eee689522ed7cd4a3303f0"
   },
   "outputs": [],
   "source": [
    "# def objective(space):\n",
    "#     mod = lgb.LGBMRegressor(n_estimators = 5000, \n",
    "#             num_leaves = int(space['num_leaves']),\n",
    "#             subsample = space['subsample'],min_child_weight = space['min_child_weight'],\n",
    "#             colsample_bytree=space['colsample_bytree'],\n",
    "#             learning_rate =space['learning_rate'],n_jobs=-1,\n",
    "#                 )\n",
    "# #     temp_train=copy.copy(newtrain)\n",
    "#     folds=KFold(5,random_state=100)\n",
    "#     fold_score=[]\n",
    "#     i=1\n",
    "#     st=time.time()\n",
    "#     print('=================*=================')\n",
    "#     print(space)\n",
    "#     for train_index,test_index in folds.split(X=X):\n",
    "#         mod.fit(X=X[train_index],y=y.values[train_index],eval_set=[ (X[test_index],y.values[test_index])],early_stopping_rounds=20,verbose=30,eval_metric='rmse')    \n",
    "#         score=mod.best_score_.get('valid_0').get('rmse')\n",
    "#         print('cv',i,': ', score)\n",
    "#         i=i+1\n",
    "#         fold_score.append(score)                \n",
    "#     print(\"SCORE:\") \n",
    "#     print(np.mean(fold_score))\n",
    "#     print('time',time.time()-st)\n",
    "#     return 1-np.mean(fold_score) \n",
    "\n",
    "# space ={\n",
    "#     #'max_depth':hp.quniform('max_depth',2,10,1),\n",
    "#     'num_leaves': hp.quniform('num_leaves', 200, 300, 4),\n",
    "#     'min_child_weight': hp.quniform ('min_child_weight', 1, 2, 1),\n",
    "#     'subsample': hp.quniform ('subsample', 0.8, .95,0.05),\n",
    "#     'learning_rate': hp.quniform('learning_rate', 0.01,0.2,.03),\n",
    "#    # A problem with max_depth casted to float instead of int with\n",
    "#    # the hp.quniform method.\n",
    "# #     'gamma': hp.quniform('gamma', 0, 0.6, 0.1),\n",
    "#     'colsample_bytree': hp.quniform('colsample_bytree', 0.7, .95, 0.05),\n",
    "#    }  \n",
    "# trials = Trials()\n",
    "# best = fmin(fn=objective,space=space,algo=tpe.suggest,max_evals=80)\n",
    "# print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "0e3cd2be-1a46-4f66-8f7c-9fbb95511b62",
    "_uuid": "26dc041ad0496392176d06882673d130e5219b63",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[\"price\"] = np.log(train[\"price\"]+0.001)\n",
    "train[\"price\"].fillna(-999,inplace=True)\n",
    "train[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "\n",
    "test[\"price\"] = np.log(test[\"price\"]+0.001)\n",
    "test[\"price\"].fillna(-999,inplace=True)\n",
    "test[\"image_top_1\"].fillna(-999,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee4b0666-f0be-4965-9dd9-6651d5c49b2b",
    "_uuid": "dc7dbed2a9943fa245d860de412cdef0e17a49d9"
   },
   "source": [
    "# LightGBM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "7e94bcc4-ab56-4a38-bdcf-218791e95c2c",
    "_uuid": "ac57e30cf4452005a2cb20db424d7bcf1f11d1df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 122982\n"
     ]
    }
   ],
   "source": [
    "rounds = 20000\n",
    "early_stop_rounds = 50\n",
    "lgbm_params = {\n",
    "    'objective' : 'regression',\n",
    "    'metric' : 'rmse',\n",
    "    'num_leaves' : 500,\n",
    "#     'max_depth': 15,\n",
    "    'learning_rate' : 0.021,\n",
    "    'feature_fraction' : 0.6,\n",
    "    'bagging_fraction' : .8,\n",
    "    'verbosity' : -1\n",
    "}\n",
    "\n",
    "feature_names = np.hstack([\n",
    "    count_vectorizer_desc.get_feature_names(),\n",
    "    count_vectorizer_title.get_feature_names(),\n",
    "    predictors\n",
    "])\n",
    "print('Number of features:', len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "bfa6795a-05a5-4372-88b3-531d947e0eee",
    "_uuid": "96aa1864c7cc6491d139863f9a817895d16525df"
   },
   "outputs": [],
   "source": [
    "VALID = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_desc_punct', 'words_vs_unique_description',\n",
       "       'num_unique_words_description', 'num_unique_words_title',\n",
       "       'num_words_description', 'num_words_title', 'avg_times_up_user',\n",
       "       'avg_days_up_user', 'n_user_items', 'price', 'item_seq_number',\n",
       "       'image_confidence', 'image_top_1', 'param_1', 'param_2', 'param_3',\n",
       "       'city', 'region', 'category_name', 'parent_category_name', 'user_type',\n",
       "       'lat_lon_hdbscan_cluster_05_03', 'lat_lon_hdbscan_cluster_10_03',\n",
       "       'lat_lon_hdbscan_cluster_20_03', 'city_region_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[:, predictors].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e910115-312f-4437-8ba3-9fb6f7426af8",
    "_uuid": "1a50b3e34d76019fdbfd45c3566eec09556f24cb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iii\\AppData\\Local\\conda\\conda\\envs\\tensorflow-gpu\\lib\\site-packages\\lightgbm\\basic.py:1184: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "\n",
    "x_test = scipy.sparse.hstack([\n",
    "    test_desc_counts,\n",
    "    test_title_counts,\n",
    "    test.loc[:, predictors]\n",
    "], format='csr')\n",
    "\n",
    "if VALID == True:\n",
    "    train_index, valid_index = train_test_split(np.arange(len(train)), test_size=0.1, random_state=42)\n",
    "\n",
    "    x_train = scipy.sparse.hstack([\n",
    "            train_desc_counts[train_index],\n",
    "            train_title_counts[train_index],\n",
    "            train.loc[train_index, predictors]\n",
    "    ], format='csr')\n",
    "    y_train = train.loc[train_index, target]\n",
    "\n",
    "    x_valid = scipy.sparse.hstack([\n",
    "        train_desc_counts[valid_index],\n",
    "        train_title_counts[valid_index],\n",
    "        train.loc[valid_index, predictors]\n",
    "    ], format='csr')\n",
    "    y_valid = train.loc[valid_index, target]\n",
    "\n",
    "     \n",
    "    # LGBM Dataset Formatting \n",
    "    lgtrain = lgb.Dataset(x_train, y_train,\n",
    "                    feature_name=list(feature_names),\n",
    "                    categorical_feature = categorical)\n",
    "    lgvalid = lgb.Dataset(x_valid, y_valid,\n",
    "                    feature_name=list(feature_names),\n",
    "                    categorical_feature = categorical)\n",
    "     \n",
    "    # Go Go Go\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=20000,\n",
    "        valid_sets=[lgtrain, lgvalid],\n",
    "        valid_names=['train','valid'],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=100)\n",
    "    print(\"Model Evaluation Stage\")\n",
    "    del x_valid ; x_train; gc.collect()\n",
    "\n",
    "else:\n",
    "    # LGBM Dataset Formatting \n",
    "    X = scipy.sparse.hstack([\n",
    "        train_desc_counts,\n",
    "        train_title_counts,\n",
    "        train.loc[: , predictors]\n",
    "    ], format='csr')\n",
    "    y = train.deal_probability\n",
    "    \n",
    "    lgtrain = lgb.Dataset(X, y.values,\n",
    "                    feature_name=list(feature_names),\n",
    "                    categorical_feature = categorical)\n",
    "     # Go Go Go\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=2200)\n",
    "    \n",
    "    del X; gc.collect()\n",
    "\n",
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5827b4fb-0bfc-4ef2-ab43-5be682151de8",
    "_uuid": "37cbdd3d10742d44e169a2db4386f7bb3c7b09bc"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 14))\n",
    "lgb.plot_importance(lgb_clf, max_num_features=50, ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9d49a8cc-4b52-47f4-868a-f7b3006cd9f3",
    "_uuid": "3c93c6232801704e05d2a94c38b7df77d7ed14f4"
   },
   "outputs": [],
   "source": [
    "subm = pd.read_csv('sample_submission.csv')\n",
    "subm['deal_probability'] = np.clip(lgb_clf.predict(x_test), 0, 1)\n",
    "subm.to_csv('submission_11th_2018_11_22.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"模型訓練共執行{:.2f}分\".format((time.time()-s)/60)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
